{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c05e2f-8a36-4257-bb98-dec7ca0b628a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2.31.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "     ---------------------------------------- 57.6/57.6 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting xlsx2csv\n",
      "  Downloading xlsx2csv-0.8.1-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from beautifulsoup4) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (1.25.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.3/78.3 kB 4.5 MB/s eta 0:00:00\n",
      "Installing collected packages: xlsx2csv, tqdm\n",
      "Successfully installed tqdm-4.66.1 xlsx2csv-0.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 requests tqdm\n",
    "xlsx2csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da6957f-4031-4bf3-9b05-0f0dfa3836a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from zipcodes import greater_boston_zipcodes\n",
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from xlsx2csv import Xlsx2csv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "#import logging\n",
    "\n",
    "\n",
    "WGI_URL = 'https://wgi.communityplatform.us/'\n",
    "WGI_API_BASE = 'https://wgi.communityplatform.us/platform-api/'\n",
    "STATE = 'MA'\n",
    "ORG_LIST_URL = f'{WGI_API_BASE}search/base-search?page=1&perPage=10000&orderBy=revenue&keywordType=all&resultType=all&states[]={STATE}'\n",
    "# https://wgi.communityplatform.us/platform-api/search/base-search?page=1&perPage=10000&orderBy=revenue&keywordType=all&resultType=all&states[]=MA\n",
    "IRS_SRC_URL = 'https://www.irs.gov/statistics/soi-tax-stats-annual-extract-of-tax-exempt-organization-financial-data'\n",
    "DEV_EMAIL = 'dhee.panwar@dell.com'\n",
    "#script_dir = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "API = 'https://wgi.communityplatform.us/platform-api/search/base-search?page=1&perPage=40&orderBy=revenue&keywordType=all&resultType=all&states%5B%5D=MA&onlyFilers=true&searchView=map'\n",
    "\n",
    "IRS_ORG_LIST = 'https://www.irs.gov/charities-non-profits/exempt-organizations-business-master-file-extract-eo-bmf'\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "output_folder_path = Path(os.path.join(current_directory, 'output_files'))\n",
    "input_folder_path = Path(os.path.join(current_directory, 'input_files'))\n",
    "logs = Path(os.path.join(current_directory, 'logs'))\n",
    "WGI_file = input_folder_path/'WGI'/'WGI_MA_Only_11_6_23.csv'\n",
    "\n",
    "\n",
    "def download_file(link, filepath, force=False):\n",
    "    if not os.path.exists(filepath) or force:\n",
    "        response = requests.get(link, stream=True)\n",
    "        print(response)\n",
    "        with open(filepath, 'wb') as f:\n",
    "            # 10MB chunk size\n",
    "            for chunk in tqdm(response.iter_content(chunk_size=10_000_000),\n",
    "                              desc=f'Downloading {filepath.name}'):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "\n",
    "\n",
    "def xlsx_to_csv(src, dest=None, force=False):\n",
    "    stem = src.stem\n",
    "    if dest is None:\n",
    "        dest = src.with_suffix('.csv')\n",
    "    if not os.path.exists(dest) or force:\n",
    "        print(f'Converting {stem}.xslx to {stem}.csv...')\n",
    "        print(f'This process can take upto 5-10 minutes. Please Wait!')\n",
    "        Xlsx2csv(str(src), outputencoding='utf-8').convert(str(dest))\n",
    "    #print(\"Dest\\n\")\n",
    "    #print(dest)\n",
    "    return dest\n",
    "\n",
    "\n",
    "def get_download_links():\n",
    "    \"\"\"Parse download links for excel forms from IRS website\n",
    "\n",
    "    Returns:\n",
    "        dict(int:list(dict{filename, link})): list of excel download links for each year\n",
    "    \"\"\"\n",
    "    r = requests.get(IRS_SRC_URL)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    # get all <h2> that appear before tables\n",
    "    #pint(soup)\n",
    "    h2s = filter(\n",
    "        lambda tag: tag.text.startswith(\n",
    "            'Exempt Organization Returns Filed in Calendar Year'),\n",
    "        soup.find_all('h2'))\n",
    "    download_links = {}\n",
    "    for h2 in h2s:\n",
    "        year = int(re.search(r'\\d+', h2.text).group(0))\n",
    "        table = h2.find_next()\n",
    "        ##int(table)\n",
    "        links = [{\n",
    "            'name': f'{a_tag.text} ({year})',\n",
    "            'link': a_tag['href'],\n",
    "        } for a_tag in table.find_all('a')]\n",
    "        download_links[year] = links\n",
    "    #print(download_links)\n",
    "    return download_links\n",
    "\n",
    "\n",
    "def download_raw_data(year: int, force=False):\n",
    "    \"\"\"Download excel files from the IRS website corresponding to the year and convert to CSV\n",
    "    Example of exported file: `script_dir/2021/Form 990 Extract (2021).csv`\n",
    "\n",
    "    Raises RuntimeError if something went wrong\n",
    "    Raises ValueError if year is not available to download\n",
    "\n",
    "    Args:\n",
    "        year (int): year for which files to download\n",
    "    \"\"\"\n",
    "    # https://pythonprogramming.net/introduction-scraping-parsing-beautiful-soup-tutorial/\n",
    "    # https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "    try:\n",
    "        download_links = get_download_links()\n",
    "    except requests.RequestException:\n",
    "        raise RuntimeError(f'Could not access IRS website ({IRS_SRC_URL})')\n",
    "    if not download_links:\n",
    "        raise RuntimeError('Could not parse IRS website to fetch links')\n",
    "    if year not in download_links:\n",
    "        raise ValueError(f'Year {year} is unavailable')\n",
    "\n",
    "    # download files into directory\n",
    "\n",
    "    download_folder = input_folder_path / f'{year}'\n",
    "    os.makedirs(download_folder, exist_ok=True)\n",
    "    total_contrib = 0\n",
    "    for file in download_links[year]:\n",
    "    \n",
    "        name = download_folder / file['name']\n",
    "        xlsx_file = name.with_suffix('.xlsx')\n",
    "        download_file(file['link'], xlsx_file, force=force)\n",
    "        csv_file = str(xlsx_to_csv(xlsx_file, force=force))\n",
    "        if '990-EZ' in csv_file:\n",
    "            with open(csv_file) as f:\n",
    "                total_contrib += sum(int(r['totcntrbs']) for r in csv.DictReader(f))\n",
    "        elif 'Form 990 Extract' in csv_file:\n",
    "            with open(csv_file) as f:\n",
    "                total_contrib += sum(int(r['totcntrbgfts']) for r in csv.DictReader(f))\n",
    "        #comment below\n",
    "       ## print(f'{name.stem} headers: ', end='')\n",
    "       # with open(csv_file) as f:\n",
    "       #      csv_reader = csv.reader(f, delimiter = ',')\n",
    "       #      for row in csv_reader:\n",
    "       #          print(', '.join(row))\n",
    "       #          break\n",
    "    #comment above \n",
    "    print('Completed required download and CSV conversions')\n",
    "    print('Total Contribution:', total_contrib)\n",
    "    return total_contrib\n",
    "\n",
    "\n",
    "def get_latest_wgi(force=False):\n",
    "    r = requests.get(WGI_URL)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    a_tag = soup.find('a', string='Download The List')\n",
    "    if not a_tag:\n",
    "        raise RuntimeError('Could not download WGI list from ')\n",
    "    dl_link = a_tag['href']\n",
    "    wgi_dir = input_folder_path / 'WGI'\n",
    "    os.makedirs(wgi_dir, exist_ok=True)\n",
    "    xlsx_file = wgi_dir / Path(dl_link).name\n",
    "    download_file(dl_link, xlsx_file, force=force)\n",
    "    #print(\"Get latest Wgi done!\")\n",
    "    return xlsx_to_csv(xlsx_file)\n",
    "\n",
    "\n",
    "def get_org(org_id):\n",
    "\n",
    "    # https://wgi.communityplatform.us/platform-api/organization/1776515\n",
    "    url = f'{WGI_API_BASE}organization/{org_id}'\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "\n",
    "\n",
    "def get_gba_orgs():\n",
    "    \"\"\"\n",
    "    Get orgs from the Greater Boston Area\n",
    "    \"\"\"\n",
    "    # greater_boston_zipcodes\n",
    "    orgs = requests.get(ORG_LIST_URL).json()['data']\n",
    "    org_in_state = {}\n",
    "    wg_revenue = 0\n",
    "    \n",
    "    output_file = output_folder_path/'greater_boston_orgs.csv'\n",
    "    \n",
    "    try:\n",
    "        with open(output_file) as f:\n",
    "            wg_revenue = sum(int(r['revenue']) for r in csv.DictReader(f))\n",
    "    except (FileNotFoundError, ValueError):\n",
    "        # https://wgi.communityplatform.us/platform-api/organization/1776515\n",
    "        for org in orgs:\n",
    "            org_zip = int(org['zip'])\n",
    "            if org_zip in greater_boston_zipcodes:\n",
    "                # clean data\n",
    "                org.pop('distance')\n",
    "                org.pop('icon')\n",
    "                org.pop('programId')\n",
    "                org.pop('programName')\n",
    "                org.pop('redirectUrl')\n",
    "                org.pop('relevance')\n",
    "                org['ein'] = ''\n",
    "                org_in_state[org['organizationId']] = org\n",
    "                revenue = org['revenue']\n",
    "                #print(\"Printing Revenue \\n\")\n",
    "                if isinstance(revenue, str):\n",
    "                    revenue = revenue.strip()\n",
    "                    if revenue[0] == '(' and revenue[-1] == ')':\n",
    "                        revenue = f'-{revenue[1:-1]}'\n",
    "                    if revenue == '-':\n",
    "                        revenue = 0\n",
    "                    revenue = int(revenue)\n",
    "                org['revenue'] = revenue\n",
    "                wg_revenue += revenue\n",
    "\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            future_to_org = {executor.submit(get_org, org_id): org_id for org_id in org_in_state}\n",
    "            # Order is not guaranteed even if you use a list. Use the value part above as an index\n",
    "            for future in tqdm(concurrent.futures.as_completed(future_to_org), total=len(future_to_org), desc='Downloading organization data'):\n",
    "                try:\n",
    "                    org_id = future_to_org[future]\n",
    "                    res = future.result()\n",
    "                    org_in_state[org_id]['ein'] = res['ein']\n",
    "                except ValueError as e:\n",
    "                    print(e)\n",
    "\n",
    "        with open(output_file, 'w') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=list(next(iter(org_in_state.values())).keys()))\n",
    "            writer.writeheader()\n",
    "            writer.writerows(org_in_state.values())\n",
    "    print('Organization data for Greater Boston Area found in:', output_file)\n",
    "    print('Revenue W&G organizations:', wg_revenue)\n",
    "    return wg_revenue\n",
    "\n",
    "\n",
    "def get_ma_orgs_list(force=False):\n",
    "    #Download Massachusetts Orgnaization Data from IRS\n",
    "    try:\n",
    "        r = requests.get(IRS_ORG_LIST)\n",
    "    except: \n",
    "        print(\"Unable to access IRS website check this URL {IRS_ORG_LIST}\")\n",
    "        print(r)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    a_tag = soup.find('a', string='Massachusetts')      \n",
    "    if not a_tag:\n",
    "        raise RuntimeError('Could not download Massachusetts Org list from ')       \n",
    "    dl_link = a_tag['href']\n",
    "    wgi_dir = input_folder_path \n",
    "    os.makedirs(wgi_dir, exist_ok=True)\n",
    "    csv_file = wgi_dir / Path(dl_link).name\n",
    "    download_file(dl_link, csv_file, force=force)\n",
    "    return csv_file\n",
    "\n",
    "\n",
    "def update_ein_header(data_frame):\n",
    "    updated_df = data_frame.rename(columns={'ein':'EIN'},inplace=True)\n",
    "    return updated_df\n",
    "\n",
    "###########This is for MA ####################\n",
    "#Read eo_ma file, extract EIN, Name, City Zip (Zip needs to be seprated to) \n",
    "#Create a CSV file with this file \n",
    "#Create a list data structure with EIN ( Name, City, Zip)\n",
    "#Compare the EIN and with IRS data base both 900 and 900EZ file and update the above list with, \"totcntrbs\" in 900 and ezfile \"totcntrbgfts\"\n",
    "#Generate a CSV file with this info\n",
    "\n",
    "\n",
    "def update_ma_orgs_file(file_name=None):\n",
    "    print(file_name)\n",
    "    columns_to_capture = ['EIN','NAME','STREET', 'CITY', 'STATE', 'ZIP']\n",
    "    df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "    df[['ZIP_PART_1', 'ZIP_PART_2']] = df['ZIP'].str.split('-', expand=True)\n",
    "    df = df.drop('ZIP', axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_irs_990_extract_file(file_name):\n",
    "    #print(\"Processing IRS 990 Extract File\")\n",
    "    try:\n",
    "        #print(\"trying one method!\")\n",
    "        columns_to_capture = ['ein','totcntrbgfts'] # add function to update this file\n",
    "        df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "        df.rename(columns={'ein':'EIN'},inplace=True)\n",
    "    except: \n",
    "        #print(\"trying 2nd method!\")\n",
    "        columns_to_capture = ['EIN','totcntrbgfts'] # add function to update this file\n",
    "        df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "    #print(\"Processing IRS 990 Extract file done!\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_irs_990_ez_file(file_name):\n",
    "    #print(\"Processing IRS 990 EX file\")\n",
    "    try:\n",
    "        #print(\"trying one method!\")\n",
    "        columns_to_capture = ['ein','totcntrbs'] # add function to update this file\n",
    "        df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "        df.rename(columns={'ein':'EIN'},inplace=True)\n",
    "    except: \n",
    "        #print(\"trying 2nd method!\")\n",
    "        columns_to_capture = ['EIN','totcntrbs'] # add function to update this file\n",
    "        df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "        #df.head()\n",
    "        \n",
    "    #print(\"Processing IRS 990 EX file done!\")\n",
    "    return df\n",
    "\n",
    "    \n",
    "def merge_df(first_df, second_df):\n",
    "    merged_df = pd.merge(first_df, second_df, on='EIN', how='left')\n",
    "    return merged_df    \n",
    "\n",
    "\n",
    "###########This is for Greater Boston Area####################\n",
    "# Create a list with EIN greater boston  \n",
    "# Convert index file in csv if needed\n",
    "# Read the above MA file compare it with index zip file if the zip is there in MA fill \n",
    "# Update the List with filtered info\n",
    "# Create a CSV file  with the filtered info\n",
    "\n",
    "\n",
    "def generate_gb_report(year, gb_dataframe, irs_990_extract_dataframe, irs_990_ez_dataframe):\n",
    "    try:\n",
    "        gb_dataframe.rename(columns={'ein':'EIN'},inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    gb_dataframe = merge_df(gb_dataframe, irs_990_extract_dataframe)\n",
    "    gb_dataframe = merge_df(gb_dataframe, irs_990_ez_dataframe)\n",
    "    print(\"Genrating list of organizations in Greater Boston Area...\\n\")\n",
    "    output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}/'))\n",
    "    if not output_folder_path.exists():\n",
    "        try: \n",
    "            os.makedirs(output_folder_path, exist_ok=True)\n",
    "        except:\n",
    "            print(\"File name already exists!\")\n",
    "    output_file = os.path.join(output_folder_path, f'greater_boston_report{year}.csv')\n",
    "    gb_dataframe.to_csv(output_file)\n",
    "    print(f\"Greater Boston file generated!! File location {output_file} \")\n",
    "    return gb_dataframe\n",
    "\n",
    "###########This is for Womens only in GB  ####################\n",
    "# Create a list with EIN Womens only  GB\n",
    "# Read the above MA file compare it with Given V2 April_WSO_GSO_MA.xlsx if the zip is there in MA fill \n",
    "# Update the List with filtered info\n",
    "# Create a CSV file  with the filtered info\n",
    "\n",
    "def generate_wgi_in_gb_report(year, gb_dataframe, wgi_file):\n",
    "    columns_to_capture_in_gb=['organizationName','id', 'name', 'description', 'address', 'categories','revenue','EIN', 'totcntrbgfts', 'totcntrbs']\n",
    "    columns_to_capture_in_wgi=['EIN','Name']\n",
    "    wgi_df= pd.read_csv(wgi_file, usecols = columns_to_capture_in_wgi)\n",
    "    output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}'))\n",
    "    wgi_in_gb_df = merge_df(gb_dataframe, wgi_df)\n",
    "    wgi_in_gb_df['w&g_organization'] = 'No'\n",
    "    wgi_in_gb_df.loc[wgi_in_gb_df['Name'].notnull(), 'w&g_organization'] = 'Yes'\n",
    "    wgi_in_gb_df = wgi_in_gb_df.drop(['Name'], axis=1)\n",
    "    output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}/'))\n",
    "    output_file = os.path.join(output_folder_path, f'wgi_greater_boston_report{year}.csv')\n",
    "    wgi_in_gb_df.to_csv(output_file)\n",
    "    print(f\"W&G file generated!! File location {output_file} \")\n",
    "\n",
    "def is_valid_year(year_str):\n",
    "    current_year = datetime.now().year\n",
    "    try:\n",
    "        year = int(year_str)\n",
    "        return 2018 <= year < current_year\n",
    "    except ValueError:\n",
    "        return False\n",
    "    \n",
    "def get_valid_year():\n",
    "    while True:\n",
    "        year_str = input(\"Enter the year you would like to download the file : \")\n",
    "        if is_valid_year(year_str):\n",
    "            return int(year_str)\n",
    "        else:\n",
    "            print(\"Invalid year. Please enter a valid year.\")\n",
    "            \n",
    "def generate_report(year, irs_990_extract_file, irs_990_ez_file, ma_orgs_file, greater_boston_orgs_file):\n",
    "    try: \n",
    "        ma_orgs_data = update_ma_orgs_file(ma_orgs_file)\n",
    "        irs_990_extract_dataframe = process_irs_990_extract_file(irs_990_extract_file)\n",
    "        irs_990_ez_dataframe = process_irs_990_ez_file(irs_990_ez_file)\n",
    "        ma_orgs_dataframe = merge_df(ma_orgs_data, irs_990_extract_dataframe)\n",
    "        ma_orgs_dataframe = merge_df(ma_orgs_dataframe, irs_990_ez_dataframe)\n",
    "        output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}/'))\n",
    "        if not output_folder_path.exists():\n",
    "            try: \n",
    "                os.makedirs(output_folder_path, exist_ok=True)\n",
    "            except:\n",
    "                print(f\"File name already exists!\")\n",
    "        output_file = os.path.join(output_folder_path, f'MA_orgs_report{year}.csv')\n",
    "        ma_orgs_dataframe.to_csv(output_file)\n",
    "        print(f\"MA organizations report generated Location {output_file}\")\n",
    "        #ma_orgs_dataframe.head()\n",
    "        gb_dataframe = pd.read_csv(greater_boston_orgs_file)\n",
    "        #print(gb_dataframe)\n",
    "        gb_report_dataframe = generate_gb_report(year, gb_dataframe, irs_990_extract_dataframe, irs_990_ez_dataframe) \n",
    "        generate_wgi_in_gb_report(year, gb_report_dataframe, WGI_file)\n",
    "    except: \n",
    "        print(f\"Unable to generate report contact {DEV_EMAIL}\")\n",
    "        \n",
    "                \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b1543-8e4c-4e39-ba2f-78d12716f77a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the year you would like to download the file :  2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organization data for Greater Boston Area found in: C:\\Users\\Dhee\\Desktop\\dell_Lalit\\dell_Lalit\\bwg\\output_files\\greater_boston_orgs.csv\n",
      "Revenue W&G organizations: 1007594668\n",
      "Downloading latest revenue data\n",
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Extract Documentation (2021).xlsx: 1it [00:00, 52.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Extract Documentation (2021).xslx to Extract Documentation (2021).csv...\n",
      "This process can take upto 5-10 minutes. Please Wait!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Form 990 Extract (2021).xlsx: 38it [00:14,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Form 990 Extract (2021).xslx to Form 990 Extract (2021).csv...\n",
      "This process can take upto 5-10 minutes. Please Wait!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        if not os.path.exists(output_folder_path):    \n",
    "            os.makedirs('output_files', exist_ok=True)\n",
    "        if not os.path.exists(input_folder_path):  \n",
    "            os.makedirs('input_files', exist_ok=True)\n",
    "        if not os.path.exists('logs'):  \n",
    "            os.makedirs('logs', exist_ok=True)   \n",
    "       # logging.basicConfig(filename='logs/script.log', encoding='utf-8', level=logging.DEBUG)\n",
    "        xlsx_key_list = input_folder_path/'V2_April_22_WSO_GSO_MA.xlsx'\n",
    "        #xlsx_key_list = script_dir / 'keys' / 'V2 April 22_WSO_GSO_MA.xlsx'\n",
    "        while not os.path.exists(xlsx_key_list):\n",
    "            print(f'Warning file not found: {xlsx_key_list}')\n",
    "            xlsx_key_list = Path(input('Enter keys source file: '))\n",
    "        csv_key_list = xlsx_key_list.with_suffix('.csv')\n",
    "        if not os.path.exists(csv_key_list):\n",
    "            print('Converting', xlsx_key_list.name, 'to csv')\n",
    "            Xlsx2csv(str(xlsx_key_list),\n",
    "                    outputencoding='utf-8').convert(str(csv_key_list))\n",
    "        year=get_valid_year()\n",
    "        wg_revenue = get_gba_orgs()\n",
    "        print(\"Downloading latest revenue data\")\n",
    "        wgi_latest = get_latest_wgi()\n",
    "        total_revenue = download_raw_data(year)\n",
    "        print('Percent contribution:', round(wg_revenue / total_revenue * 100, 2), '%')\n",
    "        print(f'Processing data to generate MA Orgs, Great Boston Orgs and W&G Orgs in Great Boston for year {year}')\n",
    "       \n",
    "        ma_orgs_file=get_ma_orgs_list()\n",
    "        file_990_extract_name = f'Form 990 Extract ({year}).csv'\n",
    "        file_990_ez_name = f'Form 990-EZ Extract ({year}).csv'\n",
    "        irs_990_extract_file = input_folder_path / str(year) /file_990_extract_name\n",
    "        irs_990_ez_file = input_folder_path / str(year) /file_990_ez_name\n",
    "        greater_boston_orgs_file = Path(os.path.join(current_directory, 'output_files/greater_boston_orgs.csv')) \n",
    "        try:\n",
    "            generate_report(year, irs_990_extract_file, irs_990_ez_file, ma_orgs_file, greater_boston_orgs_file)\n",
    "        except:\n",
    "            print(\"Script not working!! Please contact Dhee Panwar <{DEV_EMAIL}>\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        exc_type, exc_tb = sys.exc_info()[0], sys.exc_info()[2]\n",
    "        print(e.__repr__())\n",
    "        print(f'\\nThe error above was encountered on line {exc_tb.tb_lineno}. Please contact Dhee Panwar <{DEV_EMAIL}>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8791b2f3-111e-4c8a-ae05-b5d37de7fd96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Dhee\\\\Desktop\\\\dell_Lalit\\\\dell_Lalit\\\\bwg\\\\output_files\\\\2019\\\\2019/greater_boston_orgs.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10988\\4265783530.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#output_file = os.path.join(output_folder_path, f'{year}/greater_boston_report{year}.csv')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{year}/greater_boston_orgs.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgb_dataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcurrent_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0moutput_folder_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'output_files'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\dhee\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Dhee\\\\Desktop\\\\dell_Lalit\\\\dell_Lalit\\\\bwg\\\\output_files\\\\2019\\\\2019/greater_boston_orgs.csv'"
     ]
    }
   ],
   "source": [
    "year=2019\n",
    "output_file = os.path.join(output_folder_path, f'{year}/greater_boston_report{year}.csv')\n",
    "#output_file = os.path.join(output_folder_path, f'{year}/greater_boston_orgs.csv')\n",
    "gb_dataframe = pd.read_csv(output_file)\n",
    "current_directory = os.getcwd()\n",
    "output_folder_path = Path(os.path.join(current_directory, 'output_files'))\n",
    "input_folder_path = Path(os.path.join(current_directory, 'input_files'))\n",
    "\n",
    "\n",
    "\n",
    "wgi_file = input_folder_path/'WGI'/'WGI_MA_Only_11_6_23.csv'\n",
    "columns_to_capture_in_gb=['organizationName','id', 'name', 'description', 'address', 'categories','revenue','EIN', 'totcntrbgfts', 'totcntrbs']\n",
    "columns_to_capture_in_wgi=['EIN','Name']\n",
    "    #print(columns_to_capture_in_wgi)\n",
    "    #print(wgi_file)\n",
    "wgi_df= pd.read_csv(wgi_file, usecols = columns_to_capture_in_wgi)\n",
    "    #print(wgi_df)\n",
    "output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}'))\n",
    "    #print(output_folder_path) \n",
    "wgi_in_gb_df = merge_df(gb_dataframe, wgi_df)\n",
    "wgi_in_gb_df['w&g_organization'] = 'No'\n",
    "print(wgi_in_gb_df)\n",
    "wgi_in_gb_df.loc[wgi_in_gb_df['Name'].notnull(), 'w&g_organization'] = 'Yes'\n",
    "wgi_in_gb_df = wgi_in_gb_df.drop(['Name'], axis=1)\n",
    "print(wgi_in_gb_df)\n",
    "output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}/'))\n",
    "print(output_folder_path) \n",
    "output_file = os.path.join(output_folder_path, f'wgi_greater_boston_report{year}.csv')\n",
    "print(f\"Output file {output_file}\")\n",
    "wgi_in_gb_df.to_csv(output_file)\n",
    "print(f\"W&G file generated!! File location {output_file} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2226ea35-9d60-43ab-8ba3-9e5300073c65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  organizationId  \\\n",
      "0              0         1945744   \n",
      "1              1         1099156   \n",
      "2              2         1773668   \n",
      "3              3         1945742   \n",
      "4              4         1945765   \n",
      "...          ...             ...   \n",
      "1295        1295         2310990   \n",
      "1296        1296         2315531   \n",
      "1297        1297         2317274   \n",
      "1298        1298         2318854   \n",
      "1299        1299         2411587   \n",
      "\n",
      "                                       organizationName       id  \\\n",
      "0                                     Wellesley College  1945744   \n",
      "1                              Pathfinder International  1099156   \n",
      "2                                      Upstream USA Inc  1773668   \n",
      "3                                     Dana Hall Schools  1945742   \n",
      "4                                     Winsor School Inc  1945765   \n",
      "...                                                 ...      ...   \n",
      "1295        Friends of Lincoln Sudbury Girls Soccer Inc  2310990   \n",
      "1296              Love Your Neighbor Maternity Home Inc  2315531   \n",
      "1297                Hispanic Image Smart Womens Biz Hub  2317274   \n",
      "1298                         Mind Over Matter M O M Inc  2318854   \n",
      "1299  Women Marines Association MA 3 Captain Jennife...  2411587   \n",
      "\n",
      "                                                   name  \\\n",
      "0                                     Wellesley College   \n",
      "1                              Pathfinder International   \n",
      "2                                      Upstream USA Inc   \n",
      "3                                     Dana Hall Schools   \n",
      "4                                     Winsor School Inc   \n",
      "...                                                 ...   \n",
      "1295        Friends of Lincoln Sudbury Girls Soccer Inc   \n",
      "1296              Love Your Neighbor Maternity Home Inc   \n",
      "1297                Hispanic Image Smart Womens Biz Hub   \n",
      "1298                         Mind Over Matter M O M Inc   \n",
      "1299  Women Marines Association MA 3 Captain Jennife...   \n",
      "\n",
      "                                            description  \\\n",
      "0     Part 1: to provide an excellent liberal arts e...   \n",
      "1     Part 1: pathfinder international's mission is ...   \n",
      "2     Part 1: upstream USA's mission is to expand op...   \n",
      "3     Part 1: please see schedule o.Dana hall school...   \n",
      "4     Part 1: the winsor school provides college pre...   \n",
      "...                                                 ...   \n",
      "1295                                                NaN   \n",
      "1296                                                NaN   \n",
      "1297                                                NaN   \n",
      "1298                                                NaN   \n",
      "1299                                                NaN   \n",
      "\n",
      "                        address        city state   zip  ...          type  \\\n",
      "0                106 Central St   Wellesley    MA  2481  ...  organization   \n",
      "1                    9 Galen St   Watertown    MA  2472  ...  organization   \n",
      "2           2 Oliver St Ste 402      Boston    MA  2109  ...  organization   \n",
      "3                   PO Box 9010   Wellesley    MA  2482  ...  organization   \n",
      "4                103 Pilgrim Rd      Boston    MA  2215  ...  organization   \n",
      "...                         ...         ...   ...   ...  ...           ...   \n",
      "1295  725 Boston Post Rd Unit 5     Sudbury    MA  1776  ...  organization   \n",
      "1296           18 Overbrook Ter      Natick    MA  1760  ...  organization   \n",
      "1297               155 Essex St    Lawrence    MA  1840  ...  organization   \n",
      "1298      1 Chestnut Pl Apt 607      Quincy    MA  2169  ...  organization   \n",
      "1299             10 Pheasant Hl  Bellingham    MA  2019  ...  organization   \n",
      "\n",
      "                updatedAt updatedAtHuman  categories    revenue        EIN  \\\n",
      "0     2023-10-10 20:12:26    1 month ago       WEDUC  342459889   42103637   \n",
      "1     2023-10-10 20:32:57    1 month ago    RH,WINTL  118539615  530235320   \n",
      "2     2023-10-10 20:23:49    1 month ago          RH   60941598  352581424   \n",
      "3     2023-10-10 20:12:26    1 month ago       WEDUC   58731452   42103562   \n",
      "4     2023-10-10 20:12:27    1 month ago       WEDUC   34533035   42105842   \n",
      "...                   ...            ...         ...        ...        ...   \n",
      "1295  2023-10-10 19:34:09    1 month ago        GIRL          0  872795904   \n",
      "1296  2023-10-10 19:34:10    1 month ago  WHLTH,WHSV          0  873156559   \n",
      "1297  2023-10-10 19:34:10    1 month ago        WPSB          0  873303013   \n",
      "1298  2023-10-10 19:34:11    1 month ago       WHLTH          0  873431963   \n",
      "1299  2023-10-10 19:29:58    1 month ago        WADV          0  834002765   \n",
      "\n",
      "      totcntrbgfts  totcntrbs  \\\n",
      "0       68183815.0        NaN   \n",
      "1              NaN        NaN   \n",
      "2              NaN        NaN   \n",
      "3        4529847.0        NaN   \n",
      "4        5265015.0        NaN   \n",
      "...            ...        ...   \n",
      "1295           NaN        NaN   \n",
      "1296           NaN        NaN   \n",
      "1297           NaN        NaN   \n",
      "1298           NaN        NaN   \n",
      "1299           NaN        NaN   \n",
      "\n",
      "                                                   Name  w&g_organization  \n",
      "0                                     WELLESLEY COLLEGE                No  \n",
      "1                              PATHFINDER INTERNATIONAL                No  \n",
      "2                                                   NaN                No  \n",
      "3                                     DANA HALL SCHOOLS                No  \n",
      "4                                     WINSOR SCHOOL INC                No  \n",
      "...                                                 ...               ...  \n",
      "1295        FRIENDS OF LINCOLN SUDBURY GIRLS SOCCER INC                No  \n",
      "1296              LOVE YOUR NEIGHBOR MATERNITY HOME INC                No  \n",
      "1297                HISPANIC IMAGE SMART WOMENS BIZ HUB                No  \n",
      "1298                         MIND OVER MATTER M O M INC                No  \n",
      "1299  WOMEN MARINES ASSOCIATION MA 3 CAPTAIN JENNIFE...                No  \n",
      "\n",
      "[1300 rows x 22 columns]\n",
      "      Unnamed: 0  organizationId  \\\n",
      "0              0         1945744   \n",
      "1              1         1099156   \n",
      "2              2         1773668   \n",
      "3              3         1945742   \n",
      "4              4         1945765   \n",
      "...          ...             ...   \n",
      "1295        1295         2310990   \n",
      "1296        1296         2315531   \n",
      "1297        1297         2317274   \n",
      "1298        1298         2318854   \n",
      "1299        1299         2411587   \n",
      "\n",
      "                                       organizationName       id  \\\n",
      "0                                     Wellesley College  1945744   \n",
      "1                              Pathfinder International  1099156   \n",
      "2                                      Upstream USA Inc  1773668   \n",
      "3                                     Dana Hall Schools  1945742   \n",
      "4                                     Winsor School Inc  1945765   \n",
      "...                                                 ...      ...   \n",
      "1295        Friends of Lincoln Sudbury Girls Soccer Inc  2310990   \n",
      "1296              Love Your Neighbor Maternity Home Inc  2315531   \n",
      "1297                Hispanic Image Smart Womens Biz Hub  2317274   \n",
      "1298                         Mind Over Matter M O M Inc  2318854   \n",
      "1299  Women Marines Association MA 3 Captain Jennife...  2411587   \n",
      "\n",
      "                                                   name  \\\n",
      "0                                     Wellesley College   \n",
      "1                              Pathfinder International   \n",
      "2                                      Upstream USA Inc   \n",
      "3                                     Dana Hall Schools   \n",
      "4                                     Winsor School Inc   \n",
      "...                                                 ...   \n",
      "1295        Friends of Lincoln Sudbury Girls Soccer Inc   \n",
      "1296              Love Your Neighbor Maternity Home Inc   \n",
      "1297                Hispanic Image Smart Womens Biz Hub   \n",
      "1298                         Mind Over Matter M O M Inc   \n",
      "1299  Women Marines Association MA 3 Captain Jennife...   \n",
      "\n",
      "                                            description  \\\n",
      "0     Part 1: to provide an excellent liberal arts e...   \n",
      "1     Part 1: pathfinder international's mission is ...   \n",
      "2     Part 1: upstream USA's mission is to expand op...   \n",
      "3     Part 1: please see schedule o.Dana hall school...   \n",
      "4     Part 1: the winsor school provides college pre...   \n",
      "...                                                 ...   \n",
      "1295                                                NaN   \n",
      "1296                                                NaN   \n",
      "1297                                                NaN   \n",
      "1298                                                NaN   \n",
      "1299                                                NaN   \n",
      "\n",
      "                        address        city state   zip  ...  longitude  \\\n",
      "0                106 Central St   Wellesley    MA  2481  ... -71.308343   \n",
      "1                    9 Galen St   Watertown    MA  2472  ... -71.183661   \n",
      "2           2 Oliver St Ste 402      Boston    MA  2109  ... -71.055139   \n",
      "3                   PO Box 9010   Wellesley    MA  2482  ...  -0.001000   \n",
      "4                103 Pilgrim Rd      Boston    MA  2215  ... -71.108962   \n",
      "...                         ...         ...   ...   ...  ...        ...   \n",
      "1295  725 Boston Post Rd Unit 5     Sudbury    MA  1776  ...  -0.001000   \n",
      "1296           18 Overbrook Ter      Natick    MA  1760  ...   0.001000   \n",
      "1297               155 Essex St    Lawrence    MA  1840  ...   0.001000   \n",
      "1298      1 Chestnut Pl Apt 607      Quincy    MA  2169  ...   0.001000   \n",
      "1299             10 Pheasant Hl  Bellingham    MA  2019  ...  -0.001000   \n",
      "\n",
      "              type            updatedAt updatedAtHuman  categories    revenue  \\\n",
      "0     organization  2023-10-10 20:12:26    1 month ago       WEDUC  342459889   \n",
      "1     organization  2023-10-10 20:32:57    1 month ago    RH,WINTL  118539615   \n",
      "2     organization  2023-10-10 20:23:49    1 month ago          RH   60941598   \n",
      "3     organization  2023-10-10 20:12:26    1 month ago       WEDUC   58731452   \n",
      "4     organization  2023-10-10 20:12:27    1 month ago       WEDUC   34533035   \n",
      "...            ...                  ...            ...         ...        ...   \n",
      "1295  organization  2023-10-10 19:34:09    1 month ago        GIRL          0   \n",
      "1296  organization  2023-10-10 19:34:10    1 month ago  WHLTH,WHSV          0   \n",
      "1297  organization  2023-10-10 19:34:10    1 month ago        WPSB          0   \n",
      "1298  organization  2023-10-10 19:34:11    1 month ago       WHLTH          0   \n",
      "1299  organization  2023-10-10 19:29:58    1 month ago        WADV          0   \n",
      "\n",
      "            EIN  totcntrbgfts  totcntrbs  w&g_organization  \n",
      "0      42103637    68183815.0        NaN               Yes  \n",
      "1     530235320           NaN        NaN               Yes  \n",
      "2     352581424           NaN        NaN                No  \n",
      "3      42103562     4529847.0        NaN               Yes  \n",
      "4      42105842     5265015.0        NaN               Yes  \n",
      "...         ...           ...        ...               ...  \n",
      "1295  872795904           NaN        NaN               Yes  \n",
      "1296  873156559           NaN        NaN               Yes  \n",
      "1297  873303013           NaN        NaN               Yes  \n",
      "1298  873431963           NaN        NaN               Yes  \n",
      "1299  834002765           NaN        NaN               Yes  \n",
      "\n",
      "[1300 rows x 21 columns]\n",
      "C:\\Users\\Dhee\\Desktop\\dell_Lalit\\dell_Lalit\\bwg\\output_files\\2022\n",
      "Output file C:\\Users\\Dhee\\Desktop\\dell_Lalit\\dell_Lalit\\bwg\\output_files\\2022\\wgi_greater_boston_report2022.csv\n",
      "W&G file generated!! File location C:\\Users\\Dhee\\Desktop\\dell_Lalit\\dell_Lalit\\bwg\\output_files\\2022\\wgi_greater_boston_report2022.csv \n"
     ]
    }
   ],
   "source": [
    "output_file = os.path.join(output_folder_path, f'{year}/greater_boston_report{year}.csv')\n",
    "#gb_dataframe = pd.read_csv(output_file)\n",
    "current_directory = os.getcwd()\n",
    "output_folder_path = Path(os.path.join(current_directory, 'output_files'))\n",
    "input_folder_path = Path(os.path.join(current_directory, 'input_files'))\n",
    "\n",
    "\n",
    "wgi_file = input_folder_path/'WGI'/'WGI_MA_Only_11_6_23.csv'\n",
    "columns_to_capture_in_gb=['organizationName','id', 'name', 'description', 'address', 'categories','revenue','EIN', 'totcntrbgfts', 'totcntrbs']\n",
    "columns_to_capture_in_wgi=['EIN','Name']\n",
    "    #print(columns_to_capture_in_wgi)\n",
    "    #print(wgi_file)\n",
    "wgi_df= pd.read_csv(wgi_file, usecols = columns_to_capture_in_wgi)\n",
    "    #print(wgi_df)\n",
    "output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}'))\n",
    "    #print(output_folder_path) \n",
    "wgi_in_gb_df = merge_df(gb_dataframe, wgi_df)\n",
    "wgi_in_gb_df['w&g_organization'] = 'No'\n",
    "print(wgi_in_gb_df)\n",
    "wgi_in_gb_df.loc[wgi_in_gb_df['Name'].notnull(), 'w&g_organization'] = 'Yes'\n",
    "wgi_in_gb_df = wgi_in_gb_df.drop(['Name'], axis=1)\n",
    "print(wgi_in_gb_df)\n",
    "output_folder_path = Path(os.path.join(current_directory, f'output_files/{year}/'))\n",
    "print(output_folder_path) \n",
    "output_file = os.path.join(output_folder_path, f'wgi_greater_boston_report{year}.csv')\n",
    "print(f\"Output file {output_file}\")\n",
    "wgi_in_gb_df.to_csv(output_file)\n",
    "print(f\"W&G file generated!! File location {output_file} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e106090-d181-46cc-a3cf-431693996a43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Windows-1252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Please Cite as: Womens Philanthropy Institute, Indiana University Lilly Family School of Philanthropy &amp; DataLake, LLC. (2023). Women &amp; Girls Index [Data file]. http://www.philanthropy.iupui.edu/wgi</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIN</td>\n",
       "      <td>Name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001049015</td>\n",
       "      <td>MARSHFIELD WOMENADE INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>010163098</td>\n",
       "      <td>NATIONAL SOCIETY UNITED STATES DAUGHTERS OF 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>010199596</td>\n",
       "      <td>WOMENS BOARD OF THE MAINE MEDICAL CENTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>010211476</td>\n",
       "      <td>THE CHAPMAN HOUSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Please Cite as: Womens Philanthropy Institute, Indiana University Lilly Family School of Philanthropy & DataLake, LLC. (2023). Women & Girls Index [Data file]. http://www.philanthropy.iupui.edu/wgi  \\\n",
       "0                                                EIN                                                                                                                                                       \n",
       "1                                          001049015                                                                                                                                                       \n",
       "2                                          010163098                                                                                                                                                       \n",
       "3                                          010199596                                                                                                                                                       \n",
       "4                                          010211476                                                                                                                                                       \n",
       "\n",
       "                                          Unnamed: 1  \n",
       "0                                               Name  \n",
       "1                            MARSHFIELD WOMENADE INC  \n",
       "2  NATIONAL SOCIETY UNITED STATES DAUGHTERS OF 18...  \n",
       "3           WOMENS BOARD OF THE MAINE MEDICAL CENTER  \n",
       "4                                  THE CHAPMAN HOUSE  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_capture_in_wgi=['EIN','Name']\n",
    "    #print(columns_to_capture_in_wgi)\n",
    "    #print(wgi_file)\n",
    "#wgi_df= pd.read_csv(wgi_file, usecols = columns_to_capture_in_wgi)\n",
    "import pandas as pd\n",
    "import chardet\n",
    "print('hello')\n",
    "# Detect encoding\n",
    "with open('WGI_5.0_EIN_9-6-2023-7.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "print(result['encoding'])\n",
    "data = pd.read_csv('WGI_5.0_EIN_9-6-2023-7.csv', encoding=result['encoding'])#,usecols = columns_to_capture_in_wgi)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd50bc47-3940-41aa-bc7d-323f6a43e113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56b9a327-22ff-4673-8f25-026bc4925998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      EIN                                              NAME  \\\n",
      "0   19818                      PALMER SECOND BAPTIST CHURCH   \n",
      "1   29215                               ST GEORGE CATHEDRAL   \n",
      "2  587764                              IGLESIA BETHESDA INC   \n",
      "3  635913  MINISTERIO APOSTOLICO JESUCRISTO ES EL SENOR INC   \n",
      "4  765634                        MERCY CHAPEL INTERNATIONAL   \n",
      "\n",
      "                         STREET          CITY STATE ZIP_PART_1 ZIP_PART_2  \n",
      "0             1050 THORNDIKE ST        PALMER    MA      01069       1507  \n",
      "1                523 E BROADWAY  SOUTH BOSTON    MA      02127       4415  \n",
      "2              13 CUMMINGHAM ST        LOWELL    MA      01852       0000  \n",
      "3                  454 ESSEX ST      LAWRENCE    MA      01840       1242  \n",
      "4  75 MORTON VILLAGE DR APT 408      MATTAPAN    MA      02126       2433  \n"
     ]
    }
   ],
   "source": [
    "#!pip install pandas\n",
    "#!pip install openpyxl\n",
    "\n",
    "###########This is for MA ####################\n",
    "#Read eo_ma file, extract EIN, Name, City Zip (Zip needs to be seprated to) \n",
    "#Create a CSV file with this file \n",
    "#Create a list data structure with EIN ( Name, City, Zip)\n",
    "#Compare the EIN and with IRS data base both 900 and 900EZ file and update the above list with, \"totcntrbs\" in 900 and ezfile \"totcntrbgfts\"\n",
    "#Generate a CSV file with this info\n",
    "\n",
    "import pandas as pd\n",
    "file_name = 'eo_ma.csv' \n",
    "columns_to_capture = ['EIN','NAME','STREET', 'CITY', 'STATE', 'ZIP']\n",
    "df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "df[['ZIP_PART_1', 'ZIP_PART_2']] = df['ZIP'].str.split('-', expand=True)\n",
    "df = df.drop('ZIP', axis=1)\n",
    "print(df.head())\n",
    "#write in csv file\n",
    "#df.to_csv('MA_list.csv')\n",
    "\n",
    "\n",
    "#from openpyxl import load_workbook\n",
    "\n",
    "#wb = load_workbook(filename='22eoextract990.xlsx', read_only=True)\n",
    "#ws = wb['EIN']\n",
    "\n",
    "#for row in ws.rows:\n",
    "#    for cell in row:\n",
    "#        print(cell.value)\n",
    "\n",
    "# Close the workbook after reading\n",
    "#wb.close()\n",
    "\n",
    "\n",
    "#columns_to_capture_990 = ['EIN','totcntrbs']\n",
    "#IRS_file_990_extract_file_name = '22eoextract990.xlsx'\n",
    "#df2 = pd.read_excel(IRS_file_990_extract_file_name, usecols=columns_to_capture_990,sheet_name='Sheet1', engine='xlrd')\n",
    "#print(df2.head())\n",
    "\n",
    "\n",
    "#IRS_file_990-ez_extract_file = '22eoextractez.xlsx'\n",
    "\n",
    "#df.to_csv('MA_list.csv', index=columns_to_capture)\n",
    "#print(df.head()) # print the first 5 rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2d98514-34b8-4136-8f72-871c59e4b094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>totcntrbgfts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10018922.0</td>\n",
       "      <td>125780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10018922.0</td>\n",
       "      <td>122786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10018922.0</td>\n",
       "      <td>122782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10018923.0</td>\n",
       "      <td>15102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10018923.0</td>\n",
       "      <td>27640.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          EIN  totcntrbgfts\n",
       "0  10018922.0      125780.0\n",
       "1  10018922.0      122786.0\n",
       "2  10018922.0      122782.0\n",
       "3  10018923.0       15102.0\n",
       "4  10018923.0       27640.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from zipcodes import greater_boston_zipcodes\n",
    "import concurrent.futures\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from xlsx2csv import Xlsx2csv\n",
    "import requests\n",
    "\n",
    "#!pip install xlrd\n",
    "IRS_file_990_extract_file_name = '22eoextract990.xlsx'\n",
    "import os\n",
    "def xlsx_to_csv(src, dest=None, force=False):\n",
    "    stem = str(src)\n",
    "    if dest is None:\n",
    "        dest = src+'.csv'\n",
    "    if not os.path.exists(dest) or force:\n",
    "        print(f'Converting {stem}.xslx to {stem}.csv...')\n",
    "        Xlsx2csv(str(src), outputencoding='utf-8').convert(str(dest))\n",
    "    #print(\"Dest\\n\")\n",
    "    print(dest)\n",
    "    return dest\n",
    "# get the current working directory\n",
    "current_working_directory = os.getcwd()\n",
    "#script_dir = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "#print(script_dir)\n",
    "#file_name = xlsx_to_csv(IRS_file_990_extract_file_name, force=True)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "columns_to_capture_990 = ['EIN', 'totcntrbgfts']\n",
    "IRS_file_990_extract_file_name = '22eoextract990.xlsx.csv'\n",
    "df1 = pd.read_csv(IRS_file_990_extract_file_name, usecols=columns_to_capture_990)\n",
    "df1.head()\n",
    "\n",
    "#file_name = 'MA_list.csv'\n",
    "#df = pd.read_csv(file_name)\n",
    "\n",
    "#df3= pd.merge(df, df1, on='EIN', how='left')\n",
    "\n",
    "#IRS_file_990_ez_extract_ez_file = '22eoextractez.xlsx'\n",
    "#script_dir = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "#print(script_dir)\n",
    "#file_name = xlsx_to_csv(IRS_file_990_ez_extract_ez_file, force=True)\n",
    "#columns_to_capture_990_ez = ['ein','totcntrbs']\n",
    "#IRS_file_990_extract_ez_file= '22eoextractez.xlsx.csv'\n",
    "#df4 = pd.read_csv(IRS_file_990_extract_ez_file, usecols=columns_to_capture_990_ez)\n",
    "#df4.rename(columns={'ein':'EIN'},inplace=True)\n",
    "\n",
    "#df3= pd.merge(df3, df4, on='EIN', how='left')\n",
    "# Here you will get the combined list for contibution in MA \n",
    "#df3.to_csv('updated2.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df3.head()\n",
    "\n",
    "#df4.head()\n",
    "#df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "#import pandas as pd\n",
    "#file_name = 'eo_ma.csv' \n",
    "#columns_to_capture = ['EIN','NAME','STREET', 'CITY', 'STATE', 'ZIP']\n",
    "#df = pd.read_csv(file_name, usecols=columns_to_capture)\n",
    "#df[['ZIP_PART_1', 'ZIP_PART_2']] = df['ZIP'].str.split('-', expand=True)\n",
    "#df = df.drop('ZIP', axis=1)\n",
    "#print(df.head())\n",
    "\n",
    "#IRS_file_990-ez_extract_file = '22eoextractez.xlsx'\n",
    "#columns_to_capture_990 = ['ein','totcntrbs']\n",
    "#IRS_file_990_extract_ez_file= '22eoextract990ez.xlsx.csv'\n",
    "#df = pd.read_csv(IRS_file_990_extract_ez_file, usecols=columns_to_capture_990)\n",
    "#df.head()\n",
    "#df.to_csv('MA_list.csv', index=columns_to_capture)\n",
    "#print(df.head()) # print the first 5 rows\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc23a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#from zipcodes import greater_boston_zipcodes\n",
    "#zipcode = pd.read_excel('Index_Zip_Codes.xlsx', header=None)\n",
    "#numbers_list = zipcode.values.flatten().dropna().tolist()\n",
    "#print(numbers_list)\n",
    "\n",
    "#clean up new list of zip code\n",
    "#numbers_list = zipcode.values.flatten()\n",
    "#numbers_list = pd.Series(numbers_list).dropna().tolist()\n",
    "#print(numbers_list[8:])\n",
    "\n",
    "#zipcode.to_csv('greater_boston_zip.csv')\n",
    "\n",
    "\n",
    "###########This is for Greater Boston Area####################\n",
    "# Create a list with EIN greater boston  \n",
    "\n",
    "# Convert index file in csv if needed\n",
    "# Read the above MA file compare it with index zip file if the zip is there in MA fill \n",
    "# Update the List with filtered info\n",
    "# Create a CSV file  with the filtered info\n",
    "import pandas as pd\n",
    "df5 = pd.read_csv('output.csv')\n",
    "df5.rename(columns={'ein':'EIN'},inplace=True)\n",
    "df5.head()\n",
    "df5= pd.merge(df5, df1, on='EIN', how='left')\n",
    "df5= pd.merge(df5, df4, on='EIN', how='left')\n",
    "df5.to_csv('output_greater_boston.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9022f32-8b05-4a43-a274-8d4c29884eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting V2_April_22_WSO_GSO_MA.xlsx.xslx to V2_April_22_WSO_GSO_MA.xlsx.csv...\n",
      "V2_April_22_WSO_GSO_MA.xlsx.csv\n",
      "Converting WGI_MA_Only _11_6_23.xlsx.xslx to WGI_MA_Only _11_6_23.xlsx.csv...\n",
      "WGI_MA_Only _11_6_23.xlsx.csv\n"
     ]
    }
   ],
   "source": [
    "###########This is for Womens only in MA ####################\n",
    "# Create a list with EIN Womens only  MA\n",
    "# Read the above MA file compare it with Given V2 April_WSO_GSO_MA.xlsx if the zip is there in MA fill \n",
    "# Update the List with filtered info\n",
    "# Create a CSV file  with the filtered info\n",
    "V2_April_22_WSO_GSO_MA = 'V2_April_22_WSO_GSO_MA.xlsx' \n",
    "WGI_MA_Only_11_6_23 = 'WGI_MA_Only _11_6_23.xlsx'\n",
    "#script_dir = Path(os.path.dirname(os.path.abspath(sys.argv[0])))\n",
    "#print(script_dir)\n",
    "file_name = xlsx_to_csv(V2_April_22_WSO_GSO_MA, force=True)\n",
    "file_name = xlsx_to_csv(WGI_MA_Only_11_6_23, force=True)\n",
    "\n",
    "df6 =pd.read_csv('WGI_MA_Only _11_6_23.xlsx.csv')\n",
    "\n",
    "columns_to_capture_990 = ['EIN', 'totcntrbgfts']\n",
    "IRS_file_990_extract_file_name = '22eoextract990.xlsx.csv'\n",
    "df5 = pd.read_csv(IRS_file_990_extract_file_name, usecols=columns_to_capture_990)\n",
    "#df.head()\n",
    "\n",
    "\n",
    "df6= pd.merge(df6, df5, on='EIN', how='left')\n",
    "\n",
    "columns_to_capture_990_ez = ['ein','totcntrbs']\n",
    "IRS_file_990_extract_ez_file= '22eoextractez.xlsx.csv'\n",
    "df4 = pd.read_csv(IRS_file_990_extract_ez_file, usecols=columns_to_capture_990_ez)\n",
    "df4.rename(columns={'ein':'EIN'},inplace=True)\n",
    "\n",
    "df6= pd.merge(df6, df4, on='EIN', how='left')\n",
    "df6.head(10)\n",
    "df6.to_csv(\"wig_ma_only.csv\")\n",
    "# Here you will get the combined list for contibution in MA \n",
    "#df3.to_csv('updated2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b7ba03-7050-485f-9098-8cc7091b4bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dhee\\Desktop\\dell_Lalit\\dell_Lalit\\bwg\\input_files\\2019\\Form 990-EZ Extract (2019).csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elf</th>\n",
       "      <th>EIN</th>\n",
       "      <th>tax_pd</th>\n",
       "      <th>subseccd</th>\n",
       "      <th>totcntrbs</th>\n",
       "      <th>prgmservrev</th>\n",
       "      <th>duesassesmnts</th>\n",
       "      <th>othrinvstinc</th>\n",
       "      <th>grsamtsalesastothr</th>\n",
       "      <th>basisalesexpnsothr</th>\n",
       "      <th>...</th>\n",
       "      <th>exceeds1pct509</th>\n",
       "      <th>subtotpub509</th>\n",
       "      <th>pubsupplesub509</th>\n",
       "      <th>samepubsuppsubtot509</th>\n",
       "      <th>grsinc509</th>\n",
       "      <th>unreltxincls511tx509</th>\n",
       "      <th>subtotsuppinc509</th>\n",
       "      <th>netincunrelatd509</th>\n",
       "      <th>othrinc509</th>\n",
       "      <th>totsupp509</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E</td>\n",
       "      <td>263256538</td>\n",
       "      <td>201806</td>\n",
       "      <td>3</td>\n",
       "      <td>76123</td>\n",
       "      <td>31735</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E</td>\n",
       "      <td>510234993</td>\n",
       "      <td>201806</td>\n",
       "      <td>8</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "      <td>49707</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>751577062</td>\n",
       "      <td>201809</td>\n",
       "      <td>3</td>\n",
       "      <td>57639</td>\n",
       "      <td>43684</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E</td>\n",
       "      <td>465056753</td>\n",
       "      <td>201712</td>\n",
       "      <td>3</td>\n",
       "      <td>135219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E</td>\n",
       "      <td>383550668</td>\n",
       "      <td>201809</td>\n",
       "      <td>3</td>\n",
       "      <td>141619</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699709</td>\n",
       "      <td>699709</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>701018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  elf        EIN  tax_pd  subseccd  totcntrbs  prgmservrev  duesassesmnts  \\\n",
       "0   E  263256538  201806         3      76123        31735              0   \n",
       "1   E  510234993  201806         8        700            0          49707   \n",
       "2   E  751577062  201809         3      57639        43684              0   \n",
       "3   E  465056753  201712         3     135219            0              0   \n",
       "4   E  383550668  201809         3     141619            0              0   \n",
       "\n",
       "   othrinvstinc  grsamtsalesastothr  basisalesexpnsothr  ...  exceeds1pct509  \\\n",
       "0             0                   0                   0  ...               0   \n",
       "1           304                   0                   0  ...               0   \n",
       "2             5                   0                   0  ...               0   \n",
       "3             0                   0                   0  ...               0   \n",
       "4           238                   0                   0  ...               0   \n",
       "\n",
       "   subtotpub509  pubsupplesub509  samepubsuppsubtot509  grsinc509  \\\n",
       "0             0                0                     0          0   \n",
       "1             0                0                     0          0   \n",
       "2             0                0                     0          0   \n",
       "3             0                0                     0          0   \n",
       "4             0           699709                699709       1309   \n",
       "\n",
       "   unreltxincls511tx509  subtotsuppinc509  netincunrelatd509  othrinc509  \\\n",
       "0                     0                 0                  0           0   \n",
       "1                     0                 0                  0           0   \n",
       "2                     0                 0                  0           0   \n",
       "3                     0                 0                  0           0   \n",
       "4                     0              1309                  0           0   \n",
       "\n",
       "   totsupp509  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4      701018  \n",
       "\n",
       "[5 rows x 72 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "import pandas as pd\n",
    "def find_files_in_folder(folder_path, pattern):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "            file_paths.append(os.path.join(root, filename))\n",
    "    return file_paths\n",
    "\n",
    "year = '2019'\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "output_folder_path = Path(os.path.join(current_directory, 'output_files'))\n",
    "input_folder_path = Path(os.path.join(current_directory, 'input_files'))\n",
    "\n",
    "file_990_extract_name = f'Form 990 Extract ({year}).csv'\n",
    "file_990_ez_name = f'Form 990-EZ Extract ({year}).csv'\n",
    "folder_path = input_folder_path / year/ file_990_ez_name \n",
    "print(folder_path)\n",
    "df = pd.read_csv(folder_path)\n",
    "df.head()\n",
    "\n",
    "# Find paths for Form 900 files\n",
    "#paths_900 = find_files_in_folder(folder_path, pattern_900)\n",
    "#print(\"Paths for Form 900 files:\")\n",
    "#print(paths_900)\n",
    "\n",
    "# Find paths for Form 900-EZ files\n",
    "#paths_900_ez = find_files_in_folder(folder_path, pattern_900_ez)\n",
    "#print(\"\\nPaths for Form 900-EZ files:\")\n",
    "#print(paths_900_ez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc01d27-572f-4894-87c4-4d67b035756f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
